---
title: An Analysis of Texas High School Academic Competition Results, Part 4 - Schools
slug: analysis-texas-high-school-academics-4-schools
date: "2018-05-20"
categories: []
tags:
 - r
 - analysis
 - texas
 - academics
banner: "img/analysis-texas-high-school-academics/viz_map_tier3_byyear.gif"
---

```{r setup, include = FALSE}
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
knitr::opts_chunk$set(
  # echo = TRUE,
  echo = FALSE,
  cache = TRUE,
  # include = FALSE,
  fig.align = "center",
  # results = "asis",
  fig.width = 7,
  fig.height = 7,
  # out.width = 7,
  # out.height = 7,
  warning = FALSE,
  message = FALSE
)

```

```{r load, include = FALSE}
library("tidyverse")
library("rlang")
library("teplot")
library("teproj")
library("tetidy")
load(file.path("static", "data", "uil-v02-setup.RData"))
config$path_schools_uil <-
  "https://raw.githubusercontent.com/tonyelhabr/uil-v02/master/data/schools-uil.csv"
schools_uil <-
  config$path_schools_uil %>%
  # teproj::import_path_cleanly()
  readr::read_csv()
config$path_schools_nces_join <-
  "https://raw.githubusercontent.com/tonyelhabr/uil-v02/master/data/schools-nces-join.csv"
schools_nces_join <-
  config$path_schools_nces_join %>%
  # teproj::import_path_cleanly()
  readr::read_csv()
```

Having investigated individuals elsewhere, let's now take a look at the schools.

__NOTE:__

<i>
Although I began the examinations of competitions and individuals by looking at
volume of participation (to provide context), 
I'll skip an analogous discussion here
because the participation of schools is shown indirectly through
those analyses.)
</i>

## School Scores

Let's begin by looking at some of the same metrics shown for individual students,
but aggregated across all students for each school. In order to give the reader
some insight into school performance, I'll rank and show schools by a singular metric of performance.
To be consistent,
I'll use the same
metric used for ranking the individuals--summed percentile rank of scores (`prnk_sum`).

__NOTE:__
<i>
For the same reason stated before for showing my own scores among the individuals,
I'll include the numbers for my high school ("CLEMENS") in applicable contexts.
</i>

```{r schools_stats, include = FALSE, dependson = c("load")}
schools_stats <-
  schools_uil %>%
  add_stats_cols_by_at(cols_grp = c("school", "city"))
```

```{r html_schools_stats_filt, echo = FALSE, include = TRUE, dependson = c("load", "schools_stats")}
html_schools_stats_filt <-
  schools_stats %>%
  mutate_if(is.numeric, funs(round(., 2))) %>%
  create_kable_filt_at(
    config = config,
    col_rgx = "school"
  )
html_schools_stats_filt
```

Admittedly, there's not a lot of insight to extract from this summary regarding
individual schools. Nonetheless, it provides some useful context regarding
the magnitude of performance metric values aggregated at the school level.

To begin gaining some better understanding this list of top-performing schools,
let's break down school performance by year.

```{r schools_stats_byyear, include = FALSE, dependson = c("load")}
schools_stats_byyear <-
  schools_uil %>%
  add_stats_cols_by_at(cols_grp = c("school", "city", "year"))
schools_stats_byyear
```

Also, let's combine the performance metric values
with coordinate data to visualize where the best schools are located.

```{r html_schools_stats_byyear, echo = FALSE, include = TRUE, dependson = c("load", "schools_stats_byyear"), eval = FALSE}
html_schools_stats_byyear <-
  schools_stats_byyear %>%
  mutate_if(is.numeric, funs(round(., 2))) %>%
  create_kable_filt_at(
    config = config,
    col_rgx = "school"
  )
html_schools_stats_byyear
```

```{r visualize_map_tier3_at, include = FALSE, dependson = c("load")}
add_tier3_lab_cols_at <-
  function(data = NULL,
           col = "rnk",
           col_out_lab = "rnk_tier_lab",
           tier_base = 3,
           n_tiers = 3,
           factor = TRUE,
           add_col_numeric = TRUE,
           col_out_num = "rnk_tier") {
    tier_max <- tier_base * 10 ^ (n_tiers - 1L - 1L)
    if (tier_max > nrow(data)) {
      warning("Too many tiers specified given rows in `data`.", call. = FALSE)
      return(data)
    }
    
    is_grouped <- dplyr::is_grouped_df(data)
    if (is_grouped) {
      cols_grp_chr <- as.character(dplyr::groups(data))
      cols_grp <- rlang::syms(cols_grp_chr)
      data <- dplyr::group_by(data, !!!cols_grp)
    } else {
      cols_grp <- NULL
    }
    
    tiers <-
      tier_base * (10 ^ seq(1L - 1L, n_tiers - 1L - 1L, by = 1L))
    tier_lab_prefixes <-
      c(rep("Top ", n_tiers - 1L), "Outside top ")
    tier_labs <- paste0(tier_lab_prefixes, c(tiers, rev(tiers)[1]))

    col <- sym(col)
    col_out_lab <- sym(col_out_lab)
    
    
    ret <-
      data %>%
      mutate(
        !!col_out_lab :=
          case_when(
            !!col <= tiers[1] ~ tier_labs[1],
            !!col <= tiers[2] ~ tier_labs[2],
            TRUE ~ tier_labs[3]
          )
      )

    # NOTE: Factor first, then unfactor later if necessary.
    ret <-
      ret %>%
      mutate_at(vars(!!col_out_lab), funs(factor(., levels = rev(tier_labs))))

    if (add_col_numeric) {
      col_out_num <- sym(col_out_num)
      ret <-
        ret %>%
        mutate(!!col_out_num := as.integer(!!col_out_lab))
    }

    if (!factor) {
      ret <-
        ret %>%
        mutate_at(vars(!!col_out_lab), funs(as.character(.)))
    }
    
    ret <- ret %>% ungroup()
    
    ret
  }

visualize_map_tier3_at <-
  function(data = NULL,
           col = "rnk",
           col_frame = NULL,
           tier_base = 3,
           n_tier = 3,
           add_labels = TRUE,
           col_label = "school") {
    
    is_grouped <- dplyr::is_grouped_df(data)
    if (is_grouped) {
      cols_grp_chr <- as.character(dplyr::groups(data))
      cols_grp <- rlang::syms(cols_grp_chr)
      data <- dplyr::group_by(data, !!!cols_grp)
    } else {
      cols_grp <- NULL
    }
    
    data_map <-
      data %>%
      tetidy::rank_arrange_at(col) %>%
      add_tier3_lab_cols_at(tier_base = tier_base, n_tier = n_tier)

    rnk_tier_labs <- levels(data_map$rnk_tier_lab)

    data_tier1 <-
      data_map %>%
      filter(rnk_tier_lab == rev(rnk_tier_labs)[1])
    data_tier2 <-
      data_map %>%
      filter(rnk_tier_lab == rev(rnk_tier_labs)[2])
    data_tier3 <-
      data_map %>%
      filter(rnk_tier_lab == rev(rnk_tier_labs)[3])

    # browser()
    ret <-
      teplot::create_map_base_tx() +
      geom_point(
        data = data_tier3,
        aes_string(
          x = "lon",
          y = "lat",
          frame = col_frame,
          color = "rnk_tier_lab",
          group = NULL
        ),
        size = 1,
        alpha = 0.5
      ) +
      geom_point(
        data = data_tier2,
        aes_string(
          x = "lon",
          y = "lat",
          frame = col_frame,
          color = "rnk_tier_lab",
          group = NULL
        ),
        size = 3,
        alpha = 0.75
      ) +
      geom_point(
        data = data_tier1,
        aes_string(
          x = "lon",
          y = "lat",
          frame = col_frame,
          color = "rnk_tier_lab",
          group = NULL
        ),
        size = 5,
        alpha = 1
      ) +
      scale_alpha_continuous(range = c(0.5, 1)) +
      # scale_radius(range = c(1, 6)) +
      # scale_size_area(max_size = 6) +
      scale_color_manual(values = c("grey", "blue", "cyan")) +
      theme(legend.position = "bottom")
    
    if (add_labels & is.null(col_frame)) {
      ret <-
        ret +
        ggrepel::geom_label_repel(
          data = data_tier1,
          aes(
            x = lon,
            y = lat,
            label = school,
            group = NULL
          )
        )
    }

    ret
  }

schools_nces_distinct <-
  schools_nces_join %>% 
  distinct(school, county, lat, lon)
do_visualize_map_tier3 <-
  function(data = NULL,
           data_geo = schools_nces_distinct,
           col_frame = NULL,
           ...) {
    data %>%
      inner_join(data_geo,
                 by = c("school")) %>%
      visualize_map_tier3_at(col = "prnk_sum",
                             col_label = "school",
                             col_frame = col_frame,
                             ...) +
      theme(panel.background = element_blank()) +
      labs(title = paste0("Most Dominant Schools"),
        caption =
          paste0(
            config$viz_footer,
            str_wrap("Dominance is evaluated according to total percent rank.", 60)
          )
        )
  }
```

Now, let's visualize school dominance across years.

```{r viz_map_schools_stats_tier3_byyear, echo = FALSE, include = TRUE, fig.height = 7, fig.width = 7, dependson = c("load", "schools_stats_byyear")}
viz_map_schools_stats_tier3_byyear <-
  schools_stats_byyear %>% 
  group_by(year) %>% 
  do_visualize_map_tier3(col_frame = "year")
# gganimate::gganimate(
#   viz_map_schools_stats_tier3_byyear,
#   interval = 0.5
# )
if(config$export_viz) {
  # gganimate::gganimate_save(
  gganimate::gganimate(
    viz_map_schools_stats_tier3_byyear,
    filename = file.path(config$dir_viz, "viz_map_schools_stats_tier3_byyear.gif"),
    saver = "gif",
    # interval = 0.5,
    fps = 2,
    loop = 0
  )
}
```

```{r viz_map_schools_stats_tier3_byyear_gif, echo = FALSE, include = TRUE, fig.align = "center", eval = FALSE}
# ![](../figs/viz_map_tier3_byyear.gif))
# knitr::include_graphics("../figs/viz_map_schools_stats_tier3_byyear.gif")

```

![](img/analysis-texas-high-school-academics/viz_map_tier3_byyear.gif)

```{r viz_map_schools_stats_tier3, echo = FALSE, include = FALSE, fig.height = 7, fig.width = 7, dependson = c("load", "school_stats")}
# Now, if we aggregate across years (as we did before), who and where are the best of the best?
viz_map_schools_stats_tier3 <-
  schools_stats %>%
  do_visualize_map_tier3()
viz_map_schools_stats_tier3

teproj::export_ext_png(
  viz_map_schools_stats_tier3,
  export = config$export_viz,
  dir = config$dir_viz,
  units = "in", 
  height = 7,
  width = 7
)
```


We saw elsewhere that there is no
significant temporal trend for competition types or competition level, but is
there some kind of temporal trend for schools? My intuition says that there should __not__
be any kind of significant relationship between year and performance. Rather, I
would guess that--going with the theory that certain schools tend
to do well all of the time--the school itself should have some non-trivial
relationship with performance. (If this is true, this would imply that the top-performing schools
have students that are better suited for these academic competitions, perhaps due
to a strong support group of teachers, demographics, house income, or some other factor
not quantified directly here.)
Also, I hypothesize that recent
performance is probably the strongest indicator of current performance, as it
is in many different contexts. I should note that I think these things may only be shown
to be true when also factoring in competition type--it seems more likely that 
schools are "elite" for certain competition types, as opposed to all competitions in aggregate.

To put these ideas together more plainly, I am curious to know if the success of a school in any given year
can be predicted as a function of the school itself, the year, and the school's performance 
in the previous year. [^previous]
As before, my preference for quantifying performance is percent rank sum (`prnk_sum`) of team score 
(relative to other schools at a given competition level). 
Also, I think it's a good idea to "re-scale" the year value
to have a first value of 1 (corresponding to the first year in the scraped data--2004), 
with subsequent years taking on subsequent integer values. (This variable is named `year_idx`).

[^previous]:
Actually, I don't specifically enforce the criteria that the previous year is used.
Rather, I use the most recent year's value, which may or may not be the previous year
if the school did not compete in the previous year.

So, to be explicit, a [linear regression model](https://en.wikipedia.org/wiki/Linear_regression)
of the following form is calculated
for each unique school and competition type. (Accounting for competition type
allows us to properly model the reality that a given school may excel in some competition types
but not others.)

$$
prnk\_sum = intercept + prnk\_sum_{year-1} * \beta_{1} + year\_idx * \beta_{2}
$$

Note that, because this formula is applied to each school-competition type pair,
the intercept term corresponds to the school entity itself.

```{r schools_stats_bycomp_terms, include = FALSE, dependson = c("load")}
fmla_fit <- formula(prnk_sum ~ year_idx + lag(prnk_sum, 1))
schools_stats_bycomp_terms <-
  schools_uil %>%
  add_stats_cols_by_at(cols_grp = c("school", "city", "conf", "comp", "year")) %>% 
  group_by(school, city, conf, comp) %>%
  mutate(year_idx = row_number(year)) %>% 
  mutate(year_idx_max = max(year_idx)) %>% 
  ungroup() %>% 
  # filter(school == "CLEMENTS") %>% 
  group_by(school, city, comp) %>% 
  nest() %>%
  mutate(fit = purrr::map(data, ~try({lm(fmla_fit, data = .x)}, silent = TRUE))) %>%
  mutate(cls = purrr::map_chr(fit, class)) %>% 
  filter(cls != "try-error") %>%
  select(-cls) %>% 
  mutate(terms = purrr::map(fit, ~broom::tidy(.x))) %>%
  unnest(terms, .drop = TRUE) %>%
  filter(!is.nan(p.value)) %>% 
  arrange(p.value)
schools_stats_bycomp_terms
```

```{r viz_schools_stats_bycomp_pv, echo = FALSE, include = TRUE, fig.height = 7, fig.width = 7, dependson = c("load", "schools_stats_bycomp_terms")}
convert_formula_to_chr <-
  function(formula = NULL) {
    stopifnot(is_formula(formula))
    paste(formula[2], formula[3], sep = "~")
  }
lab_title_schools_stats_bycomp_pv <-
  str_wrap("Distribution of P-Values for Linear Regression Models", 60)
lab_subtitle_schools_stats_bycomp_pv <-
    paste0(convert_formula_to_chr(fmla_fit))
lab_caption_schools_stats_bycomp_pv <-
  paste0(
    config$viz_footer, 
    str_wrap(
      paste0(
        "The strongly left-skewed distribution for the lag 1 term indicates that very recent success ",
        "is most predictive of success in any given year. ",
        "Nonetheless, the even distribution of the year term indicates that year ",
        "has no significant predictive value."
      ), 100
    )
  )

viz_schools_stats_bycomp_pv <-
  schools_stats_bycomp_terms %>% 
  # filter(str_detect(term, "year")) %>% 
  ggplot(aes(x = p.value)) +
  geom_histogram(binwidth = 0.05) +
  facet_wrap( ~ term, scales = "fixed") +
  teplot::theme_te_facet_dx() +
  labs(
    title = lab_title_schools_stats_bycomp_pv,
    subtitle = lab_subtitle_schools_stats_bycomp_pv,
    caption = lab_caption_schools_stats_bycomp_pv,
    x = "P-Value",
    y = "Count"
  )
viz_schools_stats_bycomp_pv

teproj::export_ext_png(
  viz_schools_stats_bycomp_pv,
  export = config$export_viz,
  dir = config$dir_viz,
  units = "in", 
  height = 7,
  width = 7
)
```

The distribution of [p-values](https://en.wikipedia.org/wiki/P-value)
for each term in the model provide some insight
regarding the predictive power of the variables. Visually, it does seem like
two of my hypotheses are valid:

1. Recent performance does seem to be predictive
of school performance in a given competition type in any given year.

2. Year itself is not predictive
(meaning that there is no temporal trend indicating that performance
improves or worsens over time).


However, my other thought that school itself has some kind of predictive value
does __not__ appear to be true. [^Robinson]

[^Robinson]:
For more information regarding interpretation of p-value distributions, I recommend
reading [David Robinson](http://varianceexplained.org/)'s
[very helpful blog post](http://varianceexplained.org/statistics/interpreting-pvalue-histogram/)
on the topic.

Perhaps the deduction that, in general, individual schools do __not__ tend to dominate
the rest of the competition can be comprehended in another way.
The distribution of the percentage of possible opponent schools
defeated at each competition level for each school should re-enforce this inference.


```{r viz_schools_n_defeat_pct, include = TRUE, fig.height = 7, fig.width = 7, dependson = c("load")}
schools_n_defeat <-
  schools_uil %>% 
  group_by(comp, conf, complvl, year) %>% 
  mutate(n_defeat_pct  = (n_defeat + 1) / n_bycomp) %>% 
  ungroup()

viz_schools_n_defeat_pct <-
  schools_n_defeat %>% 
  # filter(complvl != "District") %>% 
  group_by(school, city, conf, complvl) %>% 
  summarise_at(vars(n_defeat_pct), funs(mean)) %>% 
  ungroup() %>% 
  ggplot(aes(x = n_defeat_pct)) +
  geom_histogram(bins = 20) +
  scale_x_continuous(labels = scales::percent) +
  facet_wrap( ~ complvl, scales = "free_y") +
  teplot::theme_te_facet_dx() +
  labs(
    title = str_wrap("School-Specific Average % of Total Possible Competitors Defeated, by Competition Level", 60),
    caption = config$viz_footer,
    x = "% of Competitors Defeated",
    y = "Count"
  )
viz_schools_n_defeat_pct

teproj::export_ext_png(
  viz_schools_n_defeat_pct,
  export = config$export_viz,
  dir = config$dir_viz,
  units = "in", 
  height = 7,
  width = 7
)
```

Indeed, observing that the histograms do __not__ show any noticeable skew to the right
supports the notion that, in general, individual schools are not dominating specific competition types.
If this theory were true, we would see some non-trivial right-hand skew.
This possibility is closest to being true (albeit not that close)
with the District level of competition (i.e. the lowest level of competition).
This observation is not all so surprising given that if it were true that
schools do dominate at some level of competition, it is most likely to be true at
the lowest level of competition.

## Wrap-Up

Certainly analysis of schools in these academic UIL competitions
deserves some more attention than that given here, but I think some of the
biggest questions about school performance have been answered.
