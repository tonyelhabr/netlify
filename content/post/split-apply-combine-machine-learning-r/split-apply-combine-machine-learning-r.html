---
title: The Split-Apply-Combine Technique for Machine Learning with R
slug: split-apply-combine-machine-learning-r
date: "2018-08-05"
categories:
  - r
tags:
  - r
  - tidyverse
  - caret
  - machine learning
image:
  caption: ""
header:
  caption: ""
  image: "split-apply-combine-machine-learning-r/purrrify_caret-banner.png"
  preview: true
params:
  eval: false
---

<script src="/rmarkdown-libs/htmlwidgets/htmlwidgets.js"></script>
<script src="/rmarkdown-libs/viz/viz.js"></script>
<link href="/rmarkdown-libs/DiagrammeR-styles/styles.css" rel="stylesheet" />
<script src="/rmarkdown-libs/grViz-binding/grViz.js"></script>


<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>Much discussion in the R community has revolved around the proper way to implement the <a href="https://www.google.com/search?q=split+apply+combine&amp;rlz=1C1GGRV_enUS751US752&amp;oq=split+apply+combine&amp;aqs=chrome..69i57j69i60l2.2919j0j4&amp;sourceid=chrome&amp;ie=UTF-8">“split-apply-combine”</a>. In particular, I love the exploration of this topic <a href="https://coolbutuseless.bitbucket.io/2018/03/03/split-apply-combine-my-search-for-a-replacement-for-group_by---do/">in this blog post</a>. It seems that the “preferred” approach is <code>dplyr::group_by()</code> + <code>tidyr::nest()</code> for splitting, <code>dplyr::mutate()</code> + <code>purrr::map()</code> for applying, and <code>tidyr::unnest()</code> for combining.</p>
<p>Additionally, many in the community have shown implementations of the <a href="http://r4ds.had.co.nz/many-models.html">“many models”</a> approach in <code>{tidyverse}</code>-style pipelines, often also using the <code>{broom}</code> package. For example, see any one of Dr. Simon J’s many blog posts on machine learning, such as <a href="https://drsimonj.svbtle.com/k-fold-cross-validation-with-modelr-and-broom">this one on k-fold cross validation</a>.</p>
<p>However, I haven’t seen as much exploration of how to apply the split-apply-combine technique to machine learning with the <code>{caret}</code> package, which is perhaps the most popular “generic” <code>R</code> machine learning package (along with <code>{mlr}</code>). One interesting write-up that I found on this subject is <a href="https://rsangole.netlify.com/post/pur-r-ify-your-carets/">this one by Rahul S.</a>. Thus, I was inspired to experiment with my own <code>{tidyverse}</code>-like pipelines using <code>{caret}</code>. (I actually used these techniques in my homework solutions to the <a href="https://www.edx.org/">edX</a> Georgia Tech <a href="https://pe.gatech.edu/courses/introduction-analytics-modeling"><em>Introduction to Analytics Modeling</em> class</a> that I have been taking this summer.)</p>
</div>
<div id="setup" class="section level2">
<h2>Setup</h2>
<p>For this walk-through, I’ll be exploring the <code>PrimaIndiansDiabetes</code> data set provided by the <code>{mlbench}</code> package. This data set was originally collected by the <a href="https://www.niddk.nih.gov/">National Institute of Diabetes and Digestive and Kidney Diseases</a> and <a href="http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes">published as one of the many datasets available in the UCI Repository</a>. It consists of 768 rows and 9 variables. It is useful for practicing binary classification, where the <code>diabetes</code> class variable (consisting of <code>pos</code> and <code>neg</code> values) is the response which I aim to predict.</p>
<pre class="r"><code>data(&quot;PimaIndiansDiabetes&quot;, package = &quot;mlbench&quot;)</code></pre>
<pre class="r"><code>PimaIndiansDiabetes</code></pre>
<pre><code>##     pregnant glucose pressure triceps insulin mass pedigree age diabetes
## 1          6     148       72      35       0   34    0.627  50      pos
## 2          1      85       66      29       0   27    0.351  31      neg
## 3          8     183       64       0       0   23    0.672  32      pos
## 4          1      89       66      23      94   28    0.167  21      neg
## 5          0     137       40      35     168   43    2.288  33      pos
## 6          5     116       74       0       0   26    0.201  30      neg
## 7          3      78       50      32      88   31    0.248  26      pos
## 8         10     115        0       0       0   35    0.134  29      neg
## 9          2     197       70      45     543   30    0.158  53      pos
## 10         8     125       96       0       0    0    0.232  54      pos
## 11         4     110       92       0       0   38    0.191  30      neg
##  [ reached getOption(&quot;max.print&quot;) -- omitted 757 rows ]</code></pre>
<pre class="r"><code>fmla_diabetes &lt;- formula(diabetes ~ .)</code></pre>
<p>Additionally, I’ll be using the <code>{tidyverse}</code> suite of packages—most notably <code>{dplyr}</code>, <code>{purrr}</code>, and <code>{tidyr}</code>—as well as the <code>{caret}</code> package for its machine learning API.</p>
<pre class="r"><code>library(&quot;tidyverse&quot;)
library(&quot;caret&quot;)</code></pre>
</div>
<div id="traditional-caret-usage" class="section level2">
<h2>Traditional <code>{caret}</code> Usage</h2>
<p>First, I think it’s instructive to show how one might typically use <code>{caret}</code> to create individual models so that I can create a baseline with which to compare a “many models” approach.</p>
<p>So, let’s say that I want to fit a cross-validated CART (<a href="https://machinelearningmastery.com/classification-and-regression-trees-for-machine-learning/">classification and regression tree</a>) model with scaling and a grid of reasonable complexity parameter (<code>cp</code>) values. (I don’t show the output here because the code is shown purely for exemplary purposes.)</p>
<pre class="r"><code>fit_rpart &lt;-
  train(
    form = fmla_diabetes,
    data = PimaIndiansDiabetes,
    method = &quot;rpart&quot;,
    preProcess = &quot;scale&quot;,
    trControl = trainControl(method = &quot;cv&quot;, number = 5),
    metric = &quot;Accuracy&quot;,
    minsplit = 5,
    tuneGrid = data.frame(cp = 10 ^ seq(-2, 1, by = 1))
  )
fit_rpart</code></pre>
<pre><code>## CART 
## 
## 768 samples
##   8 predictor
##   2 classes: &#39;neg&#39;, &#39;pos&#39; 
## 
## Pre-processing: scaled (8) 
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 614, 614, 614, 615, 615 
## Resampling results across tuning parameters:
## 
##   cp     Accuracy  Kappa
##    0.01  0.73      0.39 
##    0.10  0.72      0.38 
##    1.00  0.65      0.00 
##   10.00  0.65      0.00 
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was cp = 0.01.</code></pre>
<p>It’s reasonable to use <code>{caret}</code> directly in the manner shown above when simply fitting one model. But, let’s say that now you want to compare the previous results with a model fit with un-scaled predictors (perhaps for pedagogical purposes. Now you copy-paste the previous statement, only modifying <code>preProcess</code> from <code>&quot;scale&quot;</code> to <code>NULL</code>.</p>
<pre class="r"><code>fit_rpart_unscaled &lt;-
  train(
    form = fmla_diabetes,
    data = PimaIndiansDiabetes,
    method = &quot;rpart&quot;,
    preProcess = NULL,
    trControl = trainControl(method = &quot;cv&quot;, number = 5),
    metric = &quot;Accuracy&quot;,
    minsplit = 5,
    tuneGrid = data.frame(cp = 10 ^ seq(-2, 1, by = 1))
  )
fit_rpart_unscaled</code></pre>
<pre><code>## CART 
## 
## 768 samples
##   8 predictor
##   2 classes: &#39;neg&#39;, &#39;pos&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 615, 614, 615, 614, 614 
## Resampling results across tuning parameters:
## 
##   cp     Accuracy  Kappa
##    0.01  0.76      0.47 
##    0.10  0.74      0.37 
##    1.00  0.65      0.00 
##   10.00  0.65      0.00 
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was cp = 0.01.</code></pre>
<p>Although I might feel bad about copying-and-pasting so much code, I end up with what I wanted.</p>
<p>But now I want to try a different method–a random forest. Now I will need to change the value of the <code>method</code> argument (to <code>&quot;rf&quot;</code>) <strong>and</strong> the value of <code>tuneGrid</code>—because there are different parameters to tune for a random forest—<strong>and</strong> remove the <code>minsplit</code> argument—because it is not applicable for the <code>caret::train()</code> method for <code>&quot;rf&quot;</code>, and, consequently, will cause an error.</p>
<pre class="r"><code>fit_rf &lt;-
  train(
    form = fmla_diabetes,
    data = PimaIndiansDiabetes,
    method = &quot;rf&quot;,
    preProcess = &quot;scale&quot;,
    trControl = trainControl(method = &quot;cv&quot;, number = 5),
    metric = &quot;Accuracy&quot;,
    tuneGrid = data.frame(mtry = c(3, 5, 7))
  )
fit_rf</code></pre>
<pre><code>## Random Forest 
## 
## 768 samples
##   8 predictor
##   2 classes: &#39;neg&#39;, &#39;pos&#39; 
## 
## Pre-processing: scaled (8) 
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 615, 615, 614, 614, 614 
## Resampling results across tuning parameters:
## 
##   mtry  Accuracy  Kappa
##   3     0.77      0.47 
##   5     0.76      0.46 
##   7     0.76      0.46 
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was mtry = 3.</code></pre>
<p>Then, what if I want to try yet another different method (with the same formula (<code>form</code>) and <code>data</code>)? I would have to continue copy-pasting like this, which, of course, can start to become tiresome. The <a href="https://tonyelhabr.rbind.io/post/dry-principle-make-a-package/">DRY principle</a> is certainly relevant here—an approach using functions to automate the re-implementation the “constants” among methods is superior.</p>
<p>Anyways, I think it is evident that a better approach than copy-pasting code endlessly can be achieved. With that said, next I’ll demonstrate two approaches. While I believe the second of these is superior because it is less verbose, I think it’s worth showing the first approach as well for instructive purposes.</p>
</div>
<div id="split-apply-combine-caret-approach-1" class="section level2">
<h2>split-apply-combine + <code>{caret}</code>, Approach #1</h2>
<p>For this first approach,</p>
<ol style="list-style-type: decimal">
<li>First, I define a “base” function that creates a list of arguments passed to <code>caret::train()</code> that are common among each of the methods to evaluate.</li>
<li>Next, I define several “method-specific” functions for <code>rpart&quot;</code>, <code>&quot;rf&quot;</code>, and <code>&quot;ranger&quot;</code> (a faster implementation of the random forest than that of the more well known <code>{randomForest}</code> package, which is used by the <code>&quot;rf&quot;</code> method for <code>caret::train()</code>). These functions return lists of parameters for <code>caret::train()</code> that are unique for each function—most notably <code>tuneGrid</code>. (The <code>{caret}</code> <a href="https://topepo.github.io/caret">package’s documentation</a> should be consulted to identify exactly which arguments must be defined.) Additionally, note that there may be parameters that are passed directly to the underlying function called by <code>caret::train()</code> (via the <code>...</code> argument). such as <code>minsplit</code> for the <code>&quot;rpart&quot;</code>. (</li>
<li>Finally, I define a <code>sprintf</code>-style function—with <code>method</code> as an argument—to call the method-specific functions (using <code>purrr::invoke()</code>).</li>
</ol>
<p>Thus, the call stack for this approach looks like this. <a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></p>
<div id="htmlwidget-1" style="width:576px;height:576px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-1">{"x":{"diagram":"\ndigraph {\n\n  graph [overlap = true, fontsize = 10]\n\n  node [shape = plaintext,\n        fontname = Arial]\n\n  a [label = \"{caret} parameters\"]\n\n  node [shape = box,\n        fontname = Arial]\n\n  b [label = \"sprintf function\"]\n  c [label = \"base {caret} function\"]\n  d [label = \"method-specific {caret} function\"]\n\n  a->b\n  b->c\n  b->d\n}","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>setup_caret_base_tree &lt;-
  function() {
    list(
      form = fmla_diabetes,
      data = PimaIndiansDiabetes,
      trControl = trainControl(method = &quot;cv&quot;, number = 5),
      metric = &quot;Accuracy&quot;
    )
  }

setup_caret_rpart &lt;-
  function() {
    list(method = &quot;rpart&quot;,
         minsplit = 5,
         tuneGrid = data.frame(cp = 10 ^ seq(-2, 1, by = 1)))
  }

setup_caret_rf &lt;-
  function() {
   list(method = &quot;rf&quot;, tuneGrid = data.frame(mtry = c(3, 5, 7)))
  }

setup_caret_ranger &lt;-
  function() {
    list(method = &quot;ranger&quot;,
         tuneGrid = 
           expand.grid(
             mtry = c(3, 5, 7),
             splitrule = c(&quot;gini&quot;),
             min.node.size = 5,
             stringsAsFactors = FALSE
            )
    )
  }

fit_caret_tree_sprintf &lt;-
  function(method, preproc = NULL) {
    invoke(
      train,
      c(
        invoke(setup_caret_base_tree),
        invoke(sprintf(&quot;setup_caret_%s&quot;, method)),
        preProcess = preproc
      )
    )
  }</code></pre>
<p>(I apologize if the <code>_tree</code> suffix with the functions defined here seems verbose, but I think this syntax servers as an informational “hint” that other functions with non-tree-based methods could be written in a similar fashion.)</p>
<p>Next, I define the “grids” of method and pre-processing specifications to pass to the functions. I define a relatively “minimal” set of different combinations in order to emphasize the functionality that is implemented (rather than the choices for methods and pre-processing).</p>
<p>Note the following:</p>
<ul>
<li>The <code>_desc</code> column(s) are purely for informative purposes—they aren’t used in the functions.</li>
<li>The <code>idx_method</code> column is defined for use as the key column in the join that it does to combine these “grid” specifications and the functions when the functions are called. (See <code>fits_diabetes_tree</code>.)</li>
<li>I want to try methods without any pre-processing, meaning that <code>preProcess</code> should be set to <code>NULL</code> in <code>caret::train()</code>. However, it is not possible (to my knowledge) to explicitly define a <code>NULL</code> in a data.frame, so I use the surrogate <code>&quot;none&quot;</code>, which gets ignored (i.e. treated as <code>NULL</code>) when passed as the value of <code>preProcess</code> to <code>caret::train()</code>.</li>
<li>The <code>method</code> and <code>preproc</code> columns are not actually used directly for this approach, but for the next one.</li>
</ul>
<pre class="r"><code>grid_preproc &lt;-
  tribble(
    ~preprocess_desc, ~preproc,
    &quot;Scaled&quot;, &quot;scale&quot;,
    &quot;Unscaled&quot;, &quot;none&quot;
  )</code></pre>
<pre class="r"><code>grid_methods_tree &lt;-
  tribble(
    ~method_desc, ~method,
    &quot;{rpart} CART&quot;, &quot;rpart&quot;,
    &quot;{randomForest} Random Forest&quot;, &quot;rf&quot;,
    &quot;{ranger} Random Forest&quot;, &quot;ranger&quot;
  ) %&gt;% 
  crossing(
    grid_preproc
  ) %&gt;% 
  unite(method_desc, method_desc, preprocess_desc, sep = &quot;, &quot;) %&gt;% 
  mutate(idx_method = row_number()) %&gt;% 
  select(idx_method, everything())
grid_methods_tree</code></pre>
<pre><code>## # A tibble: 6 x 4
##   idx_method method_desc                            method preproc
##        &lt;int&gt; &lt;chr&gt;                                  &lt;chr&gt;  &lt;chr&gt;  
## 1          1 {rpart} CART, Scaled                   rpart  scale  
## 2          2 {rpart} CART, Unscaled                 rpart  none   
## 3          3 {randomForest} Random Forest, Scaled   rf     scale  
## 4          4 {randomForest} Random Forest, Unscaled rf     none   
## 5          5 {ranger} Random Forest, Scaled         ranger scale  
## 6          6 {ranger} Random Forest, Unscaled       ranger none</code></pre>
<p>Finally, for the actual implementation, I call <code>fit_caret_tree_sprintf()</code> for each combination of method and pre-processing transformation(s). Importantly, the calls should be made in the same order as that implied by <code>grid_methods_tree</code> so that the join on <code>idx_method</code> is “valid” (in the sense that the model fit aligns with the description).</p>
<pre class="r"><code>set.seed(42)
fits_diabetes_tree_1 &lt;-
  tribble(
    ~fit,
    fit_caret_tree_sprintf(method = &quot;rpart&quot;, preproc = NULL),
    fit_caret_tree_sprintf(method = &quot;rpart&quot;, preproc = &quot;scale&quot;),
    fit_caret_tree_sprintf(method = &quot;rf&quot;, preproc = NULL),
    fit_caret_tree_sprintf(method = &quot;rf&quot;, preproc = &quot;scale&quot;),
    fit_caret_tree_sprintf(method = &quot;ranger&quot;, preproc = NULL),
    fit_caret_tree_sprintf(method = &quot;ranger&quot;, preproc = &quot;scale&quot;)
  ) %&gt;% 
  mutate(idx_method = row_number()) %&gt;% 
  left_join(grid_methods_tree) %&gt;% 
  # Rearranging so that `fit` is the last column.
  select(-fit, everything(), fit)
fits_diabetes_tree_1</code></pre>
<pre><code>## # A tibble: 6 x 5
##   idx_method method_desc                         method preproc fit       
##        &lt;int&gt; &lt;chr&gt;                               &lt;chr&gt;  &lt;chr&gt;   &lt;list&gt;    
## 1          1 {rpart} CART, Scaled                rpart  scale   &lt;S3: trai~
## 2          2 {rpart} CART, Unscaled              rpart  none    &lt;S3: trai~
## 3          3 {randomForest} Random Forest, Scal~ rf     scale   &lt;S3: trai~
## 4          4 {randomForest} Random Forest, Unsc~ rf     none    &lt;S3: trai~
## 5          5 {ranger} Random Forest, Scaled      ranger scale   &lt;S3: trai~
## 6          6 {ranger} Random Forest, Unscaled    ranger none    &lt;S3: trai~</code></pre>
<p>I get the results that I wanted, albeit with a bit more verbosity than I might have liked. (Note the repeated calls to the sprintf function.)</p>
<p>There are a couple of other things that I did not mention before about the code that I think are worth saying.</p>
<ul>
<li>If one does not wish to specify <code>tuneGrid</code>, then the implementation becomes simpler.</li>
<li>Other <code>purrr</code> functions such as <code>partial()</code> or <code>compose()</code> could possibly be used in some manner to reduce some of the redundant code to an even greater extent.</li>
<li>If one only wants to implement pre-processing for certain methods, then the method-specific functions and the sprintf function could be re-defined such that <code>preproc</code> is passed as an argument to the method-specific functions and not used in the sprintf function.</li>
</ul>
</div>
<div id="split-apply-combine-caret-approach-2" class="section level2">
<h2>split-apply-combine + <code>{caret}</code>, Approach #2</h2>
<p>For this next approach (my preferred one), the fundamental difference is with the use of the <code>grid_methods_tree</code> data.frame created before. Because the split-apply-combine recipe for this approach directly uses the <code>method</code> and <code>preproc</code> columns—recall that these are not used with the previous approach—it is necessary to use <code>grid_methods_tree</code> at the beginning of the modeling pipeline.</p>
<p>Because I use the <code>grid_methods_tree</code> columns directly, I remove much of the verbosity seen in the prior approach. Now I define a function that essentially serves the same purpose as the sprintf function defined before—it binds the lists returned by a base <code>{caret}</code> function and a method-specific <code>{caret}</code> function, as well as a value for the <code>preProcess</code> argument.</p>
<p>There is a bit of “hacky” part of the implementation here—I use a <code>switch()</code> statement in order to substitute <code>NULL</code> for <code>&quot;none&quot;</code>. As mentioned before, it does not seem possible to create a <code>NULL</code> value in a data.frame, so <code>&quot;none&quot;</code> serves as a “stand-in”. Notably, an <code>ifelse()</code> call does not work because it cannot return a <code>NULL</code>.</p>
<pre class="r"><code>fit_caret_tree &lt;-
  function(method, preproc = &quot;scale&quot;) {
    invoke(
      train,
      c(
        invoke(setup_caret_base_tree),
        invoke(sprintf(&quot;setup_caret_%s&quot;, method)),
        preProcess = switch(preproc == &quot;none&quot;, NULL, preproc)
      )
    )
  }</code></pre>
<pre class="r"><code>set.seed(42)
fits_diabetes_tree_2 &lt;-
  grid_methods_tree %&gt;%
  group_by(idx_method, method_desc) %&gt;% 
  nest() %&gt;% 
  mutate(
    fit = 
      purrr::map(data, 
                 ~fit_caret_tree(method = .x$method, preproc = .x$preproc))
  ) %&gt;% 
  ungroup()
fits_diabetes_tree_2</code></pre>
<pre><code>## # A tibble: 6 x 4
##   idx_method method_desc                         data           fit       
##        &lt;int&gt; &lt;chr&gt;                               &lt;list&gt;         &lt;list&gt;    
## 1          1 {rpart} CART, Scaled                &lt;tibble [1 x ~ &lt;S3: trai~
## 2          2 {rpart} CART, Unscaled              &lt;tibble [1 x ~ &lt;S3: trai~
## 3          3 {randomForest} Random Forest, Scal~ &lt;tibble [1 x ~ &lt;S3: trai~
## 4          4 {randomForest} Random Forest, Unsc~ &lt;tibble [1 x ~ &lt;S3: trai~
## 5          5 {ranger} Random Forest, Scaled      &lt;tibble [1 x ~ &lt;S3: trai~
## 6          6 {ranger} Random Forest, Unscaled    &lt;tibble [1 x ~ &lt;S3: trai~</code></pre>
<p>Cool! This approach complies with the modern split-apply-combine approach—<code>dplyr::group_by()</code> + <code>tidyr::nest()</code>, <code>dplyr::mutate()</code> + <code>purrr::map()</code> and <code>tidyr::unnest()</code>—and achieves the results which I sought.</p>
</div>
<div id="quantifying-model-quality" class="section level2">
<h2>Quantifying Model Quality</h2>
<p>So I’ve got the fitted models for “many models” in a single <code>tibble</code>. How do I extract the results from this? <code>{purrr}</code>’s <code>pluck()</code> function is helpful here, along with the <code>dplyr::mutate()</code>, <code>purrr::map()</code>, and <code>tidyr::unnest()</code> functions used before.</p>
<pre class="r"><code>unnest_caret_results &lt;-
  function(fit, na.rm = TRUE) {
    fit %&gt;%
      dplyr::mutate(results = map(fit, ~pluck(.x, &quot;results&quot;))) %&gt;% 
      unnest(results, .drop = TRUE)
  }</code></pre>
<p>We get the same exact results with both approaches demonstrated above, so I’ll only show the results for one here.</p>
<pre class="r"><code>summ_diabetes_tree &lt;-
  fits_diabetes_tree_2 %&gt;%
  unnest_caret_results() %&gt;%
  select(-matches(&quot;SD&quot;)) %&gt;%
  arrange(desc(Accuracy))
summ_diabetes_tree</code></pre>
<pre><code>## # A tibble: 20 x 8
##    idx_method method_desc    cp Accuracy  Kappa  mtry splitrule
##         &lt;int&gt; &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;    
##  1          4 {randomFor~ NA      0.7734 0.4881     5 &lt;NA&gt;     
##  2          5 {ranger} R~ NA      0.7669 0.4713     5 gini     
##  3          5 {ranger} R~ NA      0.7669 0.4687     3 gini     
##  4          6 {ranger} R~ NA      0.7643 0.4686     3 gini     
##  5          6 {ranger} R~ NA      0.7631 0.4694     7 gini     
##  6          6 {ranger} R~ NA      0.7630 0.4666     5 gini     
##  7          3 {randomFor~ NA      0.7630 0.4632     3 &lt;NA&gt;     
##  8          4 {randomFor~ NA      0.7630 0.4661     7 &lt;NA&gt;     
##  9          5 {ranger} R~ NA      0.7629 0.4639     7 gini     
## 10          3 {randomFor~ NA      0.7617 0.4615     7 &lt;NA&gt;     
## 11          3 {randomFor~ NA      0.7591 0.4569     5 &lt;NA&gt;     
## 12          4 {randomFor~ NA      0.7578 0.4520     3 &lt;NA&gt;     
## 13          2 {rpart} CA~  0.01   0.7501 0.4311    NA &lt;NA&gt;     
## 14          1 {rpart} CA~  0.01   0.7396 0.4144    NA &lt;NA&gt;     
## 15          1 {rpart} CA~  0.1    0.7382 0.3794    NA &lt;NA&gt;     
## 16          2 {rpart} CA~  0.1    0.7240 0.3696    NA &lt;NA&gt;     
## 17          1 {rpart} CA~  1      0.6510 0         NA &lt;NA&gt;     
## 18          1 {rpart} CA~ 10      0.6510 0         NA &lt;NA&gt;     
## 19          2 {rpart} CA~  1      0.6510 0         NA &lt;NA&gt;     
## 20          2 {rpart} CA~ 10      0.6510 0         NA &lt;NA&gt;     
## # ... with 1 more variable: min.node.size &lt;dbl&gt;</code></pre>
<p>And, with the results fashioned like this, we can easily perform other typical <code>{dplyr}</code> actions to gain insight from the results quickly.</p>
<pre class="r"><code>summ_diabetes_bymethod &lt;-
  summ_diabetes_tree %&gt;% 
  group_by(idx_method, method_desc) %&gt;% 
  summarise_at(vars(Accuracy), funs(min, max, mean, n = n())) %&gt;% 
  ungroup() %&gt;% 
  arrange(desc(max))
summ_diabetes_bymethod</code></pre>
<pre><code>## # A tibble: 6 x 6
##   idx_method method_desc                           min    max   mean     n
##        &lt;int&gt; &lt;chr&gt;                               &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;int&gt;
## 1          4 {randomForest} Random Forest, Uns~ 0.7578 0.7734 0.7647     3
## 2          5 {ranger} Random Forest, Scaled     0.7629 0.7669 0.7656     3
## 3          6 {ranger} Random Forest, Unscaled   0.7630 0.7643 0.7635     3
## 4          3 {randomForest} Random Forest, Sca~ 0.7591 0.7630 0.7613     3
## 5          2 {rpart} CART, Unscaled             0.6510 0.7501 0.6940     4
## 6          1 {rpart} CART, Scaled               0.6510 0.7396 0.6950     4</code></pre>
<p>And let’s not forget about visualizing the results.</p>
<p><img src="/post/split-apply-combine-machine-learning-r/split-apply-combine-machine-learning-r_files/figure-html/viz_summ_diabetes_bymethod_show-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="conclusion" class="section level2">
<h2>Conclusion</h2>
<p>That’s it for this tutorial. I hope that this is useful for others. (If nothing else, it’s useful for me to review.) While the <code>{caret}</code> package does allow users <a href="https://topepo.github.io/caret/using-your-own-model-in-train.html">to create custom <code>train()</code> functions</a>, I believe that this functionality is typically beyond what a user needs when experimenting with different approaches (and can be quite complex). I believe that the approach (primarily the second one) that I’ve shown in this post offers a great amount of flexibility that complements the many other aspects of <code>{caret}</code>’s user-friendly, dynamic API.</p>
<p>In an actual analysis, the approach(es) that I’ve shown can be extremely useful in experimenting with many different methods, parameters, and data pre-processing in order to identify a set that is most appropriate for the context.</p>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>This figure is created with the awesome <code>{DiagrammeR}</code> package.<a href="#fnref1">↩</a></p></li>
</ol>
</div>
